{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs the FPME algorithm on a randomly generated $(a, B, \\lambda, T)$. FPME uses QME and LPME as subroutines and consequently achieves its predictions using just oracle comparisons.\n",
    "\n",
    "Note that the FPME algorithm is even more susceptible to error than QPME because it has several $B_{ij}$ matrices, the number of which grow quadratically with the number of classes. We run trials and investigate sources of error, similar to *qme.ipynb*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from common import Sphere, normalize\n",
    "from fpme_utils import create_a_B_lamb_T, compute_B_err\n",
    "from fpme import FPME, FairOracle\n",
    "from trials import NUM_TRIALS, load_fpme_sphere, load_a_B_lamb_T, write_fpme_trial, write_fpme_trial_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "\n",
    "ng = 3 # number of groups\n",
    "nc = 3 # number of classes\n",
    "search_tol = 1e-2 # search tolerance, the smaller the more accurate\n",
    "\n",
    "q = nc ** 2 - nc # number of off-diagonal elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere = Sphere(np.random.randn(q), 1.0, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, B, lamb, T = create_a_B_lamb_T(sphere, ng, nc, q, well_formed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56421462, 0.74170966, 0.11763843, 0.03916839, 0.05216882,\n",
       "       0.33679979])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear performance metric\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.03305597, -0.01456106, -0.01000368,  0.04872265,  0.03698551,\n",
       "          0.02220856],\n",
       "        [-0.01456106,  0.17577733, -0.09262995, -0.17109535, -0.28250276,\n",
       "         -0.10267277],\n",
       "        [-0.01000368, -0.09262995,  0.14901064,  0.10878091,  0.09927939,\n",
       "          0.03541693],\n",
       "        [ 0.04872265, -0.17109535,  0.10878091,  0.3362072 ,  0.34826242,\n",
       "          0.07024184],\n",
       "        [ 0.03698551, -0.28250276,  0.09927939,  0.34826242,  0.58066695,\n",
       "          0.1473379 ],\n",
       "        [ 0.02220856, -0.10267277,  0.03541693,  0.07024184,  0.1473379 ,\n",
       "          0.11550174]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quadratic group discrepancy weights\n",
    "# try looking at B[0][2] and B[1][2]. B is symmetric, so B[i][j] = B[j][i]. \n",
    "# every B[i][j] is positive semi-definite\n",
    "B[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3271087780626641"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trade-off between fairness (lamb) and performance (1. - lamb)\n",
    "lamb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23703881, 0.23703881, 0.54231157, 0.54231157, 0.28286822,\n",
       "        0.28286822],\n",
       "       [0.57689909, 0.57689909, 0.13922037, 0.13922037, 0.32536577,\n",
       "        0.32536577],\n",
       "       [0.1860621 , 0.1860621 , 0.31846806, 0.31846806, 0.39176601,\n",
       "        0.39176601]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of `ng` vectors, each q-dimensional\n",
    "# T[i] represents P(G = g | Y = i) the g-th group\n",
    "# in matrix form, row i means Y = i. Every element in a row \n",
    "# would have the same value of P(G = g | Y = i).\n",
    "# Because we take all off-diagonal elements of the matrix, each row\n",
    "# contributes (nc - 1) repetitions of the value P(G = g | Y = i)\n",
    "# this is why you see T[0][0] = T[0][1], T[0][2] = T[0][3], ...\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\sum_i P(G = g | Y = i) = 1.0 (obviously)\n",
    "# so the sum across axis 0 must be 1 in all `q` dimensions\n",
    "np.sum(T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_oracle = FairOracle(a, B, lamb, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpm = FPME(sphere, fair_oracle, T, nc, q, ng, search_tol)\n",
    "a_hat, B_hat, lamb_hat = fpm.run_fpme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|| a_hat - a || error: 2.101765781885616e-06\n",
      "sum of|| B_hat - B ||_F error: 0.03671912632841213\n",
      "|| lamb_hat - lamb || error: 0.0002643003176973635\n"
     ]
    }
   ],
   "source": [
    "print(\"|| a_hat - a || error:\", np.square(a_hat - a).sum())\n",
    "print(\"sum of|| B_hat - B ||_F error:\", compute_B_err(B_hat, B))\n",
    "print(\"|| lamb_hat - lamb || error:\", abs(lamb_hat - lamb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trials\n",
    "\n",
    "Make sure to run all choices of $2 \\leq ng \\leq 5$ and $2 \\leq nc \\leq 5 $. Alternatively, you can run *fpme_trials_runner.py*. Even with 6-core multiprocessing, this can take over an hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = 2 # number of groups, change this as you go\n",
    "nc = 2 # number of classes, change this as you go\n",
    "q = nc ** 2 - nc\n",
    "search_tol = 1e-2\n",
    "sphere = load_fpme_sphere(ng, nc)\n",
    "\n",
    "# set this based on your system\n",
    "num_procs = 6\n",
    "\n",
    "if os.path.exists(f\"trials/fpme/m={ng},k={nc}/a_1_hat.npy\"):\n",
    "    print(\"WARNING - this class and group have already been run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUEUE_IN = mp.Queue()\n",
    "QUEUE_OUT = mp.Queue()\n",
    "\n",
    "\n",
    "def run_trial(ng, nc, q, sphere, a, B, lamb, T):\n",
    "    fair_oracle = FairOracle(a, B, lamb, T)\n",
    "    fpm = FPME(sphere, fair_oracle, T, nc, q, ng, search_tol)\n",
    "    a_hat, B_hat, lamb_hat = fpm.run_fpme()\n",
    "    return (a_hat, B_hat, lamb_hat)\n",
    "    \n",
    "\n",
    "def proc_run_trials(self_id, ng, nc, q, sphere):\n",
    "    while True:\n",
    "        data = QUEUE_IN.get(block=True)\n",
    "        if data is None:\n",
    "            QUEUE_IN.put(None) # so other threads can read this and exit out\n",
    "            break # exit\n",
    "            \n",
    "        tid, a, B, lamb, T = data\n",
    "        a_hat, B_hat, lamb_hat = run_trial(ng, nc, q, sphere, a, B, lamb, T)\n",
    "        \n",
    "        # put result into queue out\n",
    "        QUEUE_OUT.put((tid, a_hat, B_hat, lamb_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the procs\n",
    "procs = []\n",
    "for i in range(num_procs):\n",
    "    proc = mp.Process(target=proc_run_trials, args=(\n",
    "        i,\n",
    "        ng,\n",
    "        nc,\n",
    "        q,\n",
    "        sphere,\n",
    "    ))\n",
    "    proc.start()\n",
    "    procs.append(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d955e0c7e394b68b321e7ee597f5f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# put in work\n",
    "trial_ids = []\n",
    "a_list = []\n",
    "B_list = []\n",
    "lamb_list = []\n",
    "T_list = []\n",
    "for i in tqdm_notebook(range(NUM_TRIALS)):\n",
    "    a, B, lamb, T = load_a_B_lamb_T(ng, nc, i)\n",
    "    trial_ids.append(i)\n",
    "    a_list.append(a)\n",
    "    B_list.append(B)\n",
    "    lamb_list.append(lamb)\n",
    "    T_list.append(T)\n",
    "    \n",
    "    QUEUE_IN.put((i, a, B, lamb, T))\n",
    "    \n",
    "QUEUE_IN.put(None) # signal end to procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00a6077bc7a496a8993d9d03802e2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# use trial_ids_out to map into the original inputs\n",
    "trial_ids_out = []\n",
    "\n",
    "a_hat_list = []\n",
    "B_hat_list = []\n",
    "lamb_hat_list = []\n",
    "\n",
    "a_err = []\n",
    "B_err = []\n",
    "lamb_err = []\n",
    "\n",
    "# we should get trials many results from QUEUE_OUT\n",
    "for _ in tqdm_notebook(range(NUM_TRIALS)):\n",
    "    tid, a_hat, B_hat, lamb_hat = QUEUE_OUT.get(block=True)\n",
    "    \n",
    "    \n",
    "    trial_ids_out.append(tid)\n",
    "    \n",
    "    a_hat_list.append(a_hat)\n",
    "    B_hat_list.append(B_hat)\n",
    "    lamb_hat_list.append(lamb_hat)\n",
    "    \n",
    "    # compute error\n",
    "    a_err.append( np.linalg.norm(a_hat - a_list[tid]) )\n",
    "    B_err.append( compute_B_err(B_hat, B_list[tid]) )\n",
    "    lamb_err.append( abs(lamb_hat - lamb_list[tid]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_err = np.array(a_err)\n",
    "B_err = np.array(B_err)\n",
    "lamb_err = np.array(lamb_err)\n",
    "\n",
    "# save each trial result\n",
    "for i in range(NUM_TRIALS):\n",
    "    write_fpme_trial(\n",
    "        ng,\n",
    "        nc,\n",
    "        trial_ids_out[i],\n",
    "        a_hat_list[i],\n",
    "        B_hat_list[i],\n",
    "        lamb_hat_list[i],\n",
    "    )\n",
    "\n",
    "# save the trial summary\n",
    "write_fpme_trial_summary(ng, nc, a_err, B_err, lamb_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the worst_a, worst_B, worst_lamb, worst_T (showing ng=3, nc=3)\n",
    "idx_max = np.argmax(B_err)\n",
    "worst_wid = trial_ids_out[idx_max]\n",
    "worst_a = a_list[worst_wid]\n",
    "worst_B = B_list[worst_wid]\n",
    "worst_lamb = lamb_list[worst_wid]\n",
    "worst_T = T_list[worst_wid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_oracle = FairOracle(worst_a, worst_B, worst_lamb, worst_T)\n",
    "# check_i checks for gradient inconsistencies; looks at hidden oracle metric to check as it goes\n",
    "fpm = FPME(sphere, fair_oracle, worst_T, nc, q, ng, search_tol, check_i=True)\n",
    "a_hat_worst, B_hat_worst, lamb_hat_worst = fpm.run_fpme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28492094, 0.73093798, 0.29697729, 0.19358889, 0.25988883,\n",
       "       0.43741897])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28440754, 0.73167139, 0.29704216, 0.1940933 , 0.25972501,\n",
       "       0.43635536])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_hat_worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.06527192,  0.05205754,  0.0659426 ,  0.06457812, -0.03249433,\n",
       "         -0.02951271],\n",
       "        [ 0.05205754,  0.07730736,  0.07098818,  0.05337472, -0.03373242,\n",
       "         -0.02305348],\n",
       "        [ 0.0659426 ,  0.07098818,  0.1097586 ,  0.07098079, -0.02957892,\n",
       "         -0.03862351],\n",
       "        [ 0.06457812,  0.05337472,  0.07098079,  0.09863198, -0.02757556,\n",
       "         -0.03422091],\n",
       "        [-0.03249433, -0.03373242, -0.02957892, -0.02757556,  0.03627449,\n",
       "          0.02260286],\n",
       "        [-0.02951271, -0.02305348, -0.03862351, -0.03422091,  0.02260286,\n",
       "          0.02940696]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_B[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.03355392, -0.00941103,  0.03155446,  0.03811908, -0.04213113,\n",
       "         -0.0489406 ],\n",
       "        [-0.00941103, -0.06863972,  0.0056803 ,  0.00719691, -0.07539014,\n",
       "         -0.08064389],\n",
       "        [ 0.03155446,  0.0056803 ,  0.05262294,  0.04305149, -0.04135206,\n",
       "         -0.06328642],\n",
       "        [ 0.03811908,  0.00719691,  0.04305149,  0.06548701, -0.03638539,\n",
       "         -0.04738475],\n",
       "        [-0.04213113, -0.07539014, -0.04135206, -0.03638539,  0.010444  ,\n",
       "         -0.00184444],\n",
       "        [-0.0489406 , -0.08064389, -0.06328642, -0.04738475, -0.00184444,\n",
       "         -0.0135987 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretty bad\n",
    "B_hat_worst[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a squared error 0.0014893703178208634\n",
      "B total squared error 0.6126578673873865\n",
      "lambda amount off 0.04092549043298693\n"
     ]
    }
   ],
   "source": [
    "print(\"a squared error\", np.linalg.norm(a_hat_worst - worst_a))\n",
    "print(\"B total squared error\", compute_B_err(B_hat_worst, worst_B))\n",
    "print(\"lambda amount off\", abs(lamb_hat_worst - worst_lamb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no inconsistencies, this means the error can entirely be attributed to fractions\n",
    "fpm.inconsistencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to prove the assertion that this is just due to fractions\n",
    "# we will try using the optimal QME result instead of the estimated\n",
    "# see qme.ipynb for an example of how even cosine similarities of 1e-6 on \n",
    "# gradient estimations can still lead to significant errors\n",
    "fpm = FPME(sphere, fair_oracle, worst_T, nc, q, ng, search_tol)\n",
    "a_hat_worst_opt, B_hat_worst_opt, lamb_hat_worst_opt = fpm.run_fpme(solve_opt_qme=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a squared error 0.0014893703178208634\n",
      "B total squared error 6.097029387475627e-15\n",
      "lambda amount off 3.65871811358609e-05\n"
     ]
    }
   ],
   "source": [
    "# note this can still have some error because a is still estimated, which can also affected \\lambda\n",
    "print(\"a squared error\", np.linalg.norm(a_hat_worst - worst_a))\n",
    "# B error has gone to 0\n",
    "print(\"B total squared error\", compute_B_err(B_hat_worst_opt, worst_B))\n",
    "print(\"lambda amount off\", abs(lamb_hat_worst_opt - worst_lamb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, even on the worst trial there were no inconsistencies (optimal gradients for all $B$ were extremely close to the measured gradients). However, using the measured gradients still resulted in large error. We can see that using the true gradients (using flag *solve_opt_qme=True*) makes the error disappear. **Thus, the error can be entirely attributed to QME. In *qme.ipynb* we show that error in QME can be entirely attributed to the fact that fractions are not robust to error.** We know it is not code error because we use the same algorithm on the true gradients and get the right answer. Evidently, this bad output CAN happen for some random inputs $(a, B, \\lambda, T)$. Furthermore, if you look at the plot for the error (below) you will see that it is severely right-tailed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([53., 23.,  5.,  8.,  6.,  1.,  1.,  0.,  1.,  2.]),\n",
       " array([0.0095168 , 0.06983091, 0.13014502, 0.19045912, 0.25077323,\n",
       "        0.31108734, 0.37140144, 0.43171555, 0.49202965, 0.55234376,\n",
       "        0.61265787]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(B_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([70., 18.,  6.,  1.,  0.,  1.,  1.,  1.,  0.,  2.]),\n",
       " array([4.77551472e-05, 5.19969122e-03, 1.03516273e-02, 1.55035634e-02,\n",
       "        2.06554994e-02, 2.58074355e-02, 3.09593716e-02, 3.61113076e-02,\n",
       "        4.12632437e-02, 4.64151798e-02, 5.15671158e-02]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lamb_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
